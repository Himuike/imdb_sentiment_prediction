











import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings("ignore")





from google.colab import files
uploaded = files.upload()
df=pd.read_csv("IMDB_Dataset.csv")


df.head()


df.info()











import re   # Regex Library
def clean_text(text):
    text=re.sub(r'<.*?>','',text) # Remove html tag
    text=re.sub(r'[^a-zA-Z]',' ',text) # Remove non-alphabetic character
    text=text.lower()  # Converts to lowercase
    return text
df["review"]=df["review"].apply(clean_text)
df.head()





import nltk # NLP Library
from nltk.corpus import stopwords

nltk.download("stopwords")
stop_words=set(stopwords.words("english"))

def remove_stopwords(text):
    words=text.split()
    filtered=[word for word in words if word not in stop_words]
    return ' '.join(filtered)
df["review"]=df["review"].apply(remove_stopwords)
df.head()





from nltk.stem import WordNetLemmatizer
from nltk.corpus import wordnet

nltk.download("wordnet")
nltk.download("omw-1.4")
lemmatizer=WordNetLemmatizer()

def lemmatize_text(text):
    words=text.split()
    Lemmatized=[lemmatizer.lemmatize(word) for word in words if word not in stop_words]
    return ' '.join(Lemmatized)
df["review"]=df["review"].apply(lemmatize_text)
df.head()





df["sentiment"]=df["sentiment"].map({"positive": 1,"negative": 0})
df.head()


df.head()








from wordcloud import WordCloud
import matplotlib.pyplot as plt
positive_text = ' '.join(df[df['sentiment'] == 1]['review'])
negative_text = ' '.join(df[df['sentiment'] == 0]['review'])

wordcloud_positive = WordCloud(width=800, height=400).generate(positive_text)
wordcloud_negative = WordCloud(width=800, height=400).generate(negative_text)

plt.figure(figsize=(15, 7))
plt.subplot(1, 2, 1)
plt.imshow(wordcloud_positive, interpolation='bilinear')
plt.axis('off')
plt.title('Positive Reviews')

plt.subplot(1, 2, 2)
plt.imshow(wordcloud_negative, interpolation='bilinear')
plt.axis('off')
plt.title('Negative Reviews')
plt.show()





import matplotlib.pyplot as plt
df["review_length"]=df["review"].apply(lambda x: len(x.split()))
plt.hist(df["review_length"],bins=50)
plt.xlabel("Review Length")
plt.ylabel("Frequency")
plt.title("Distribution of Review Lengths")
plt.show()





df.head()








from tensorflow.keras.preprocessing.text import Tokenizer
tokenizer=Tokenizer(num_words=5000)  # 5000 most frequent words
tokenizer.fit_on_texts(df["review"])
sequences=tokenizer.texts_to_sequences(df["review"])


# Save the tokenizer to a file
import pickle
with open("tokenizer.pkl", "wb") as f:
    pickle.dump(tokenizer, f)





from tensorflow.keras.preprocessing.sequence import pad_sequences
maxlen=100
X=pad_sequences(sequences,maxlen=maxlen)
y=df["sentiment"].values





from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)








from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding,GlobalAveragePooling1D,Dense

ann_model=Sequential()
ann_model.add(Embedding(input_dim=5000,output_dim=128,input_length=maxlen))
ann_model.add(GlobalAveragePooling1D())
ann_model.add(Dense(64,activation="relu"))
ann_model.add(Dense(1,activation="sigmoid"))


# compile the model
ann_model.compile(loss="binary_crossentropy",optimizer="adam",metrics=["accuracy"])


# Train ANN Model
ann_history = ann_model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.2)





from sklearn.metrics import classification_report
loss, accuracy = ann_model.evaluate(X_test, y_test)
print(f'ANN Test Accuracy: {accuracy * 100:.2f}%')
y_pred_ann = (ann_model.predict(X_test) > 0.5).astype("int32")
print(classification_report(y_test, y_pred_ann))








sample = ["The movie was absolutely wonderful, a masterpiece!"]


sample_seq = tokenizer.texts_to_sequences(sample)
sample_pad = pad_sequences(sample_seq, maxlen=maxlen)
prediction = ann_model.predict(sample_pad)
sentiment = 'Positive' if prediction[0][0] > 0.5 else 'Negative'
print(f"Sentiment: {sentiment}")





from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Conv1D,Dense,Dropout,GlobalMaxPooling1D

cnn_model = Sequential()
# Embedding Layer
cnn_model.add(Embedding(input_dim=5000,output_dim=128,input_length=maxlen))
# Convolutional layer
cnn_model.add(Conv1D(filters=128,kernel_size=5,activation="relu"))
cnn_model.add(GlobalMaxPooling1D()) # Most important features
cnn_model.add(Dense(64,activation="relu"))
cnn_model.add(Dropout(0.5))
cnn_model.add(Dense(1,activation="sigmoid"))
# Compile the model
cnn_model.compile(loss="binary_crossentropy",optimizer="adam",metrics=["accuracy"])


cnn_history=cnn_model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.2)


cnn_model.save("cnn_model.h5")





loss, accuracy = cnn_model.evaluate(X_test, y_test)
print(f'CNN Test Accuracy: {accuracy * 100:.2f}%')
y_pred_cnn = (cnn_model.predict(X_test) > 0.5).astype("int32")
print(classification_report(y_test, y_pred_cnn))








sample = ["The movie was absolutely wonderful, a masterpiece!"]
sample_seq = tokenizer.texts_to_sequences(sample)
sample_pad = pad_sequences(sample_seq, maxlen=maxlen)
prediction = cnn_model.predict(sample_pad)
sentiment = 'Positive' if prediction[0][0] > 0.5 else 'Negative'
print(f"Sentiment: {sentiment}")





from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout

rnn_model = Sequential()
rnn_model.add(Embedding(input_dim=5000, output_dim=128, input_length=maxlen))
rnn_model.add(SimpleRNN(128, return_sequences=False))  # basic RNN layer
rnn_model.add(Dropout(0.5))
rnn_model.add(Dense(1, activation='sigmoid'))
# Compile
rnn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])


rnn_history = rnn_model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.2)





loss, accuracy = rnn_model.evaluate(X_test, y_test)
print(f'RNN Test Accuracy: {accuracy * 100:.2f}%')
y_pred_rnn = (rnn_model.predict(X_test) > 0.5).astype("int32")
print(classification_report(y_test, y_pred_rnn))








sample = ["The movie was absolutely wonderful, a masterpiece!"]
sample_seq = tokenizer.texts_to_sequences(sample)
sample_pad = pad_sequences(sample_seq, maxlen=maxlen)
prediction = rnn_model.predict(sample_pad)
sentiment = 'Positive' if prediction[0][0] > 0.5 else 'Negative'
print(f"Sentiment: {sentiment}")





from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout

lstm_model = Sequential()
lstm_model.add(Embedding(input_dim=5000, output_dim=128, input_length=maxlen))
lstm_model.add(LSTM(128))
lstm_model.add(Dropout(0.5))
lstm_model.add(Dense(1, activation='sigmoid'))

lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])


lstm_history = lstm_model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.2)





loss, accuracy = lstm_model.evaluate(X_test, y_test)
print(f'LSTM Test Accuracy: {accuracy * 100:.2f}%')
y_pred_lstm = (lstm_model.predict(X_test) > 0.5).astype("int32")
print(classification_report(y_test, y_pred_lstm))








sample = ["The movie was absolutely wonderful, a masterpiece!"]
sample_seq = tokenizer.texts_to_sequences(sample)
sample_pad = pad_sequences(sample_seq, maxlen=maxlen)
prediction = lstm_model.predict(sample_pad)
sentiment = 'Positive' if prediction[0][0] > 0.5 else 'Negative'
print(f"Sentiment: {sentiment}")





from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dropout, Dense

bilstm_model = Sequential()
bilstm_model.add(Embedding(input_dim=5000, output_dim=128, input_length=maxlen))
bilstm_model.add(Bidirectional(LSTM(128)))
bilstm_model.add(Dropout(0.5))
bilstm_model.add(Dense(1, activation='sigmoid'))

bilstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])


bilstm_history = bilstm_model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.2)





loss, accuracy = bilstm_model.evaluate(X_test, y_test)
print(f'BiLSTM Test Accuracy: {accuracy * 100:.2f}%')
y_pred_bilstm = (bilstm_model.predict(X_test) > 0.5).astype("int32")
print(classification_report(y_test, y_pred_bilstm))








sample = ["The movie was absolutely wonderful, a masterpiece!"]
sample_seq = tokenizer.texts_to_sequences(sample)
sample_pad = pad_sequences(sample_seq, maxlen=maxlen)
prediction = bilstm_model.predict(sample_pad)
sentiment = 'Positive' if prediction[0][0] > 0.5 else 'Negative'
print(f"Sentiment: {sentiment}")





# Accuracy summary
model_names = ['ANN', 'CNN', 'RNN', 'LSTM', 'BiLSTM']
accuracies = [87.20, 86.65, 85.06, 85.46, 85.46]

import matplotlib.pyplot as plt

plt.figure(figsize=(8,5))
plt.bar(model_names, accuracies, color='skyblue')
plt.ylabel('Test Accuracy (%)')
plt.title('Model Performance Comparison')
plt.ylim(80, 88)
plt.show()



